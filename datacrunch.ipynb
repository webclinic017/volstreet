{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import volstreet.datamodule as dm\n",
    "import plotly.express as px\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.optimize import curve_fit\n",
    "from datetime import time, datetime, timedelta\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import volstreet as vs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Using DataClient class\n",
    "client = dm.DataClient(api_key=__import__('os').environ['EOD_API_KEY'])\n",
    "kite_user = __import__('os').environ['KITE_USER']\n",
    "kite_pass = __import__('os').environ['KITE_PASS']\n",
    "kite_api_key = __import__('os').environ['KITE_API_KEY']\n",
    "kite_api_secret = __import__('os').environ['KITE_API_SECRET']\n",
    "kite_auth_key = __import__('os').environ['KITE_AUTH_KEY']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Using get_data and analyser functions\n",
    "nifty_data = client.get_data(symbol='NIFTY')\n",
    "bnf_data = client.get_data(symbol='BANKNIFTY')\n",
    "finnifty_data = client.get_data(symbol='FINNIFTY')\n",
    "nifty_daily_data = dm.analyser(nifty_data, frequency='D')\n",
    "bnf_daily_data = dm.analyser(bnf_data, frequency='D')\n",
    "nifty_weekly_data = dm.analyser(nifty_data, frequency='W-THU')\n",
    "bnf_weekly_data = dm.analyser(bnf_data, frequency='W-THU')\n",
    "nifty_monthly_data = dm.analyser(nifty_data, frequency='M-THU')\n",
    "bnf_monthly_data = dm.analyser(bnf_data, frequency='M-THU')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Using ratio_analysis function\n",
    "rolling_periods = 5\n",
    "ratio_data = dm.ratio_analysis(bnf_weekly_data, nifty_weekly_data, add_rolling=rolling_periods)\n",
    "px.line(ratio_data, x=ratio_data.index, y=['BANKNIFTY Change', 'NIFTY Change', f'Rolling {rolling_periods} Ratio'], color_discrete_map={'BANKNIFTY Change': 'red', 'NIFTY Change': 'blue', f'Rolling {rolling_periods} Ratio': 'green'})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ratio_data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Using gambler function for NIFTY and BANKNIFTY\n",
    "for index in ['NIFTY', 'BANKNIFTY']:\n",
    "    print(f'{index}\\n')\n",
    "    data = client.get_data(symbol=index)\n",
    "    for frequency in ['D', 'D-THU', 'W-THU', 'M-THU']:\n",
    "        print(f'{frequency}\\n')\n",
    "        dm.gambler(data, frequency, 'abs_change')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Using gambler function for FINNIFTY\n",
    "for index in ['FINNIFTY']:\n",
    "    print(f'{index}\\n')\n",
    "    data = client.get_data(symbol=index)\n",
    "    for frequency in ['D', 'D-TUE', 'W-TUE', 'M-TUE']:\n",
    "        print(f'{frequency}\\n')\n",
    "        dm.gambler(data, frequency, 'abs_change')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Rolling average of absolute change to support gambler function\n",
    "analysed_df = dm.analyser(finnifty_data, frequency='W-tue')\n",
    "rolling_periods = 9\n",
    "analysed_df['rolling'] = analysed_df['abs_change'].rolling(rolling_periods, min_periods=1).mean()\n",
    "px.line(analysed_df, x=analysed_df.index, y='rolling')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "analysed_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# One min data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "kite_obj = dm.get_greenlit_kite(kite_api_key, kite_api_secret, kite_user, kite_pass, kite_auth_key)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dm.get_1m_data(kite_obj, 'SBILIFE', path='data\\\\')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Updating one min data for NIFTY 50, NIFTY BANK and NIFTY FIN SERVICE\n",
    "dm.get_1m_data(kite_obj, 'NIFTY 50', path='data\\\\')\n",
    "dm.get_1m_data(kite_obj, 'NIFTY BANK', path='data\\\\')\n",
    "dm.get_1m_data(kite_obj, 'NIFTY FIN SERVICE', path='data\\\\')\n",
    "dm.get_1m_data(kite_obj, 'NIFTY MID SELECT', path='data\\\\')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dm.get_constituent_1m_data(kite_obj, 'NIFTY', path='data\\\\')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Intraday Trend"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "nifty_onemin = pd.read_csv('data/NIFTY 50_onemin_prices.csv', index_col=0, parse_dates=True)\n",
    "bnf_onemin = pd.read_csv('data/NIFTY BANK_onemin_prices.csv', index_col=0, parse_dates=True)\n",
    "fin_onemin = pd.read_csv('data/NIFTY FIN SERVICE_onemin_prices.csv', index_col=0, parse_dates=True)\n",
    "midcp_onemin = pd.read_csv('data/NIFTY MID SELECT_onemin_prices.csv', index_col=0, parse_dates=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trend_nifty = dm.backtest_intraday_trend(nifty_onemin, open_nth = 0, beta = 0.8, eod_client=client, max_entries=3)\n",
    "trend_bnf = dm.backtest_intraday_trend(bnf_onemin, open_nth = 0, beta = 0.8, eod_client=client, max_entries=3)\n",
    "trend_finnifty = dm.backtest_intraday_trend(fin_onemin, open_nth = 0, beta = 0.8, eod_client=client, max_entries=3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trend_bnf"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plotting the distribution of returns for various entries\n",
    "df_to_plot = trend_finnifty\n",
    "returns_1 = df_to_plot.trade_data.apply(lambda x: x.get('entry_1', {}).get('returns', np.nan)).dropna()\n",
    "returns_2 = df_to_plot.trade_data.apply(lambda x: x.get('entry_2', {}).get('returns', np.nan)).dropna()\n",
    "returns_3 = df_to_plot.trade_data.apply(lambda x: x.get('entry_3', {}).get('returns', np.nan)).dropna()\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Histogram(x=returns_1, name='Entry 1', nbinsx=10))\n",
    "fig.add_trace(go.Histogram(x=returns_2, name='Entry 2', nbinsx=10))\n",
    "fig.add_trace(go.Histogram(x=returns_3, name='Entry 3', nbinsx=10))\n",
    "fig.update_layout(barmode='overlay')\n",
    "fig.update_traces(opacity=0.75)\n",
    "fig.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Year wise summary of returns\n",
    "df_to_sum = trend_nifty\n",
    "df_to_sum.groupby(df_to_sum.index.year).total_returns.sum()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_indices_returns = trend_bnf.merge(trend_finnifty, left_index=True, right_index=True, suffixes=('_bnf', '_finnifty')).merge(trend_nifty, left_index=True, right_index=True, suffixes=('', '_nifty'))[['total_returns', 'total_returns_bnf', 'total_returns_finnifty']]\n",
    "all_indices_returns"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plotting the distribution of the ratio for stop loss and no stop loss days for all indices\n",
    "all_indices_with_drivers = pd.concat([trend_nifty, trend_bnf, trend_finnifty])\n",
    "all_indices_with_drivers_stop_loss =  all_indices_with_drivers[(all_indices_with_drivers.total_returns <= 0)]\n",
    "all_indices_with_drivers_no_stop_loss =  all_indices_with_drivers[(all_indices_with_drivers.total_returns > 0)]\n",
    "fig = px.histogram(all_indices_with_drivers_stop_loss, x='ratio')\n",
    "fig.add_trace(go.Histogram(x=all_indices_with_drivers_no_stop_loss.ratio, name='No Stop Loss'))\n",
    "fig.update_layout(barmode='overlay')\n",
    "fig.update_traces(opacity=0.75)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plotting the minute vol and open to close trend on different y axis\n",
    "df_to_plot = trend_finnifty\n",
    "fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "fig.add_trace(go.Line(x=df_to_plot.index, y=df_to_plot['rolling_ratio'], name='Ratio'), secondary_y=True)\n",
    "fig.add_trace(go.Line(x=df_to_plot.index, y=df_to_plot['strat_nav'], name='Nav'), secondary_y=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Trying different beta values\n",
    "for beta in range(80, 105, 5):\n",
    "    beta = beta/100\n",
    "    trend_nifty = dm.backtest_intraday_trend(nifty_onemin, beta = beta, eod_client=client)\n",
    "    print(f'Beta: {beta}')\n",
    "    print(f'NIFTY: {trend_nifty[\"total_returns\"].sum()}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Intraday Trend - Constituent analysis"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_index_with_constituent_trend_data(index_name, trend_df):\n",
    "\n",
    "    index_onemin = pd.read_csv(f'data/{index_name}_onemin_prices.csv', index_col=0, parse_dates=True)\n",
    "    index_daily_open = (index_onemin.groupby(index_onemin.index.date).apply(lambda x: x.iloc[1]).open.to_frame())\n",
    "    index_onemin['day_open'] = index_daily_open.loc[index_onemin.index.date].values\n",
    "    index_onemin['change_from_open'] = index_onemin['close'] / index_onemin['day_open'] - 1\n",
    "    index_onemin = index_onemin[['change_from_open']]\n",
    "    index_onemin.columns = map(lambda x: f'{index_name}_{x}', index_onemin.columns)\n",
    "    tickers, weights = vs.get_index_constituents(index_name)\n",
    "    ticker_dfs = []\n",
    "    for ticker, weight in zip(tickers, weights):\n",
    "        ticker_onemin = pd.read_csv(f'data/{ticker}_onemin_prices.csv', index_col=0, parse_dates=True)\n",
    "        ticker_onemin['weight'] = weight/100\n",
    "        ticker_daily_open = (ticker_onemin.groupby(ticker_onemin.index.date).apply(lambda x: x.iloc[1]).open.to_frame())\n",
    "        ticker_onemin['day_open'] = ticker_daily_open.loc[ticker_onemin.index.date].values\n",
    "        ticker_onemin['change_from_open'] = ticker_onemin['close'] / ticker_onemin['day_open'] - 1\n",
    "        ticker_onemin['weighted_change'] = ticker_onemin['change_from_open'] * ticker_onemin['weight']\n",
    "        ticker_onemin = ticker_onemin[['change_from_open', 'weighted_change']]\n",
    "        ticker_onemin.columns = map(lambda x: f'{ticker}_{x}', ticker_onemin.columns)\n",
    "        ticker_dfs.append(ticker_onemin)\n",
    "    full_df = pd.concat(ticker_dfs, axis=1)\n",
    "    full_df['proxy_index_change'] = full_df.filter(regex='weighted_change').sum(axis=1)\n",
    "    full_df = full_df.merge(index_onemin, left_index=True, right_index=True)\n",
    "    for ticker in tickers:\n",
    "        full_df[f'{ticker}_contribution'] = full_df[f'{ticker}_weighted_change'] / full_df[f'proxy_index_change']\n",
    "        full_df[f'{ticker}_contribution_sq'] = full_df[f'{ticker}_contribution'] ** 2\n",
    "    _trigger_times = [day[entry]['trigger_time'] for day in trend_df.trade_data for entry in day.keys() if entry != 'total_returns']\n",
    "    _returns = [day[entry]['returns'] for day in trend_df.trade_data for entry in day.keys() if entry != 'total_returns']\n",
    "    _trend_at_close = [trend_df.set_index(trend_df.index.date).loc[tt.date()].open_to_close_trend for tt in _trigger_times]\n",
    "    _trigger_returns_trend = pd.DataFrame({'trigger_time': _trigger_times, 'returns': _returns, 'trend_at_close': _trend_at_close})\n",
    "    df_to_ret = full_df.merge(_trigger_returns_trend, left_index=True, right_on='trigger_time')\n",
    "    df_to_ret['sum_of_abs_movement'] = df_to_ret.drop(columns=[f'{index_name}_change_from_open']).filter(regex='change_from_open').abs().sum(axis=1)\n",
    "    df_to_ret['std_of_ratio'] = df_to_ret.drop(columns=[f'{index_name}_change_from_open']).filter(regex='change_from_open').div(df_to_ret['sum_of_abs_movement'], axis=0).std(axis=1)\n",
    "    df_to_ret['std_of_constituents'] = df_to_ret.drop(columns=[f'{index_name}_change_from_open']).filter(regex='change_from_open').std(axis=1)\n",
    "    df_to_ret['hhi_index'] = df_to_ret.filter(regex='contribution_sq').sum(axis=1)\n",
    "\n",
    "\n",
    "    return df_to_ret"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trend_bnf_consolidated = get_index_with_constituent_trend_data('NIFTY BANK', trend_bnf)\n",
    "trend_bnf_consolidated_post_2021 = trend_bnf_consolidated[trend_bnf_consolidated.trigger_time > datetime(2021, 1, 1)]\n",
    "trend_bnf_consolidated_post_2021"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trend_nifty_consolidated = get_index_with_constituent_trend_data('NIFTY 50', trend_nifty)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trend_nifty_consolidated_post_2023 = trend_nifty_consolidated[trend_nifty_consolidated.trigger_time > datetime(2023, 1, 1)]\n",
    "trend_nifty_consolidated_post_2023"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "px.scatter(trend_bnf_consolidated_post_2021, x='std_of_constituents', y='std_of_ratio', hover_data=['trigger_time', 'returns', 'trend_at_close'], color='returns', range_color=[-0.3, 1])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Index flat vs constituents move"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bnf_index_vs_cons =  dm.get_index_vs_constituents_recent_vols('BANKNIFTY', return_all=False, simulate_backtest=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bnf_index_vs_cons"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Insights"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Confirming that there is a certain drift in absolute changes as time frame increases\n",
    "\n",
    "for index_name, daily_df in zip(['NIFTY', 'BANKNIFTY', 'FINNIFTY'], [nifty_data, bnf_data, finnifty_data]):\n",
    "\n",
    "    daily_vol = daily_df.resample('B').ffill().close.pct_change().abs().mean()\n",
    "    weekly_vol = daily_df.resample('W').ffill().close.pct_change().abs().mean()\n",
    "    monthly_vol = daily_df.resample('M').ffill().close.pct_change().abs().mean()\n",
    "    yearly_vol = daily_df.resample('Y').ffill().close.pct_change().abs().mean()\n",
    "\n",
    "    weekly_ratio = weekly_vol / daily_vol\n",
    "    monthly_ratio = monthly_vol / daily_vol\n",
    "    yearly_ratio = yearly_vol / daily_vol\n",
    "\n",
    "    weekly_benchmark = 5**0.5\n",
    "    monthly_benchmark = 21**0.5\n",
    "    yearly_benchmark = 252**0.5\n",
    "\n",
    "    weekly_deviation_from_benchmark = weekly_ratio/weekly_benchmark\n",
    "    monthly_deviation_from_benchmark = monthly_ratio/monthly_benchmark\n",
    "    yearly_deviation_from_benchmark = yearly_ratio/yearly_benchmark\n",
    "\n",
    "    print(f'{index_name}\\nDaily Volatility: {daily_vol:0.3f}\\nWeekly Volatility: {weekly_vol: 0.3f}, Weekly Ratio: {weekly_ratio: 0.3f}, Weekly Benchmark: {weekly_benchmark: 0.3f}\\nMonthly Volatility: {monthly_vol: 0.3f}, Monthly Ratio: {monthly_ratio: 0.3f}, Monthly Benchmark: {monthly_benchmark: 0.3f}\\nYearly Volatility: {yearly_vol: 0.3f}, Yearly Ratio: {yearly_ratio: 0.3f}, Yearly Benchmark: {yearly_benchmark: 0.3f}\\n')\n",
    "\n",
    "    print(f'{index_name}\\nWeekly Deviation from Benchmark: {weekly_deviation_from_benchmark: 0.3f}\\nMonthly Deviation from Benchmark: {monthly_deviation_from_benchmark: 0.3f}\\nYearly Deviation from Benchmark: {yearly_deviation_from_benchmark: 0.3f}\\n')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Confirming whether drift is present in intraday movements\n",
    "\n",
    "for onemindf, index_name in zip([nifty_onemin, bnf_onemin, fin_onemin, midcp_onemin], ['NIFTY', 'BANKNIFTY', 'FINNIFTY', 'MIDCAP']):\n",
    "    print(f'{index_name}\\n')\n",
    "\n",
    "    filtered_index = filter(lambda i: i.time() not in [time(9, 15), time(9, 16), time(15, 30)], onemindf.index)\n",
    "    filtered_index = list(filtered_index)\n",
    "\n",
    "    minute_vol_sd = onemindf.close.pct_change()[filtered_index].std()\n",
    "    minute_vol_abs_change = onemindf.close.pct_change()[filtered_index].abs().mean()\n",
    "\n",
    "\n",
    "    print(f'Minute Volatility SD: {minute_vol_sd}')\n",
    "    print(f'Minute Volatility Absolute Change: {minute_vol_abs_change}')\n",
    "\n",
    "    open_close_std = onemindf.close.groupby(onemindf.index.date).apply(lambda x: (x.iloc[-1] / x.iloc[0] - 1)).std()\n",
    "    open_close_abs_change = onemindf.close.groupby(onemindf.index.date).apply(lambda x: (x.iloc[-1] / x.iloc[0] - 1)).abs().mean()\n",
    "\n",
    "    print(f'Open Close SD: {open_close_std}')\n",
    "    print(f'Open Close Absolute Change: {open_close_abs_change}')\n",
    "\n",
    "    ratio_of_volatility = open_close_std / minute_vol_sd\n",
    "    ratio_of_abs_change = open_close_abs_change / minute_vol_abs_change\n",
    "\n",
    "    print(f'Ratio of Volatility: {ratio_of_volatility}')\n",
    "    print(f'Ratio of Absolute Change: {ratio_of_abs_change}\\n')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Determining the distribution of one min volatility\n",
    "df = bnf_onemin\n",
    "filtered_index = filter(lambda i: i.time() not in [time(9, 15), time(9, 16), time(15, 30)], df.index)\n",
    "filtered_index = list(filtered_index)\n",
    "filtered_df = df.close.pct_change()[filtered_index]\n",
    "px.histogram(x=filtered_df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Modelling IV surface"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Modelling IV surface\n",
    "vol_surface = pd.read_csv('data/vol_surface.csv', index_col=0)\n",
    "#vol_surface = vol_surface.drop(vol_surface[vol_surface.isna().all(axis=1)].index)\n",
    "vol_surface['tte'] = vol_surface.time_to_expiry.apply(lambda num: round(num, 4))\n",
    "vol_surface"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Modelling IV surface\n",
    "vol_surface_dict = {}\n",
    "for tte in vol_surface.tte.unique():\n",
    "    X = vol_surface.loc[vol_surface.tte == tte][['distance', 'distance_squared']]\n",
    "    y = vol_surface.loc[vol_surface.tte == tte]['iv_multiple']\n",
    "    model = LinearRegression()\n",
    "    model.fit(X, y)\n",
    "    dis_sq_coeff, dis_coeff, intercept = model.coef_[1], model.coef_[0], model.intercept_\n",
    "    score = model.score(X, y)\n",
    "    if score > 0.9:\n",
    "        vol_surface_dict[tte] = {'dis_sq_coeff': dis_sq_coeff, 'dis_coeff': dis_coeff, 'intercept': intercept, 'score': score}\n",
    "    # print(f'{tte} days to expiry: Coefficients: {model.coef_}, Intercept: {model.intercept_}, R2: {model.score(X, y)}')\n",
    "vol_surface_weights = pd.DataFrame(vol_surface_dict).T.reset_index().rename(columns={'index': 'time_to_expiry'})\n",
    "vol_surface_weights.sort_values('time_to_expiry', inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "vol_surface_weights"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig = px.scatter(vol_surface_weights, x='time_to_expiry', y='dis_sq_coeff')\n",
    "fig.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def func(x, a, b, c):\n",
    "    return a * np.exp(-b * x) + c\n",
    "lower_bounds = [-np.inf, -np.inf, -np.inf]\n",
    "upper_bounds = [np.inf, np.inf, np.inf]\n",
    "popt, pcov = curve_fit(func, vol_surface_weights['time_to_expiry'], vol_surface_weights['dis_sq_coeff'], bounds=(lower_bounds, upper_bounds))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dummy_range = np.arange(0, 1, 0.0001)\n",
    "fig.add_trace(px.line(x=dummy_range, y=func(dummy_range, *popt)).data[0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "popt"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Modelling IV surface - Distance Squared coefficient vs Time to Expiry (inverse)\n",
    "for param in np.arange(0.02, 1.5, 0.01):\n",
    "    vol_surface_weights['tte_inverse'] = 1 / (vol_surface_weights.time_to_expiry**param)\n",
    "    X = vol_surface_weights['tte_inverse'].values.reshape(-1, 1)\n",
    "    y = vol_surface_weights['dis_coeff']\n",
    "    model = LinearRegression()\n",
    "    model.fit(X, y)\n",
    "    print(f'{param} param: Coefficients: {model.coef_}, Intercept: {model.intercept_}, R2: {model.score(X, y)}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "px.scatter(vol_surface_weights, x='time_to_expiry', y='dis_coeff')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def coefficients_for_surface(tte):\n",
    "\n",
    "    # distance squared coefficient\n",
    "    dfs2 = 3270.27*np.exp(-384.38*tte) + 100\n",
    "    dfs2 = min(dfs2, 20000)\n",
    "\n",
    "    # distance coefficient\n",
    "    if tte < 0.26/365:\n",
    "        dfs = 1\n",
    "    else:\n",
    "        dfs = 1 / ((tte ** 0.45) * 5)\n",
    "        dfs = min(dfs, 5)\n",
    "        dfs = -6 + dfs\n",
    "\n",
    "    # intercept\n",
    "    if tte<3/(24*365):\n",
    "        intercept=1.07\n",
    "    elif tte<0.27/365:\n",
    "        intercept=1\n",
    "    else:\n",
    "        intercept=0.98\n",
    "    return dfs2, dfs, intercept"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "coefficients_for_surface(2/365)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
